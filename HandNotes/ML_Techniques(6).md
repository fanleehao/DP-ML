## 机器学习技法（6）

ML 

------

### Lecture 6 Support Vector Regression

### 复习

1. 任何一种L2正则化的线性模型都可以使用核函数转化

   ![1537067132002](assets/1537067132002.png)

2. 如何把普通的回归regression问题进行核函数的转化？？

### 回归的核化

1. 数学上的推导过程如下：

   ![1537067581390](assets/1537067581390.png)

2. 求解？？

   ![1537067848556](assets/1537067848556.png)

3. 对比和经验结论

   ![1537067960914](assets/1537067960914.png)



### LSSVM 

1. 使用核化的回归求解分类问题——LSSVM

2. 管道回归——一般的回归问题中或者LSSVM中，求得的直接结果比较密集，我们希望能够得到一个更加稀疏的解。

   - 误差度量的方式：

     ![1537068430599](assets/1537068430599.png)

   - TODO：

     ![1537068452593](assets/1537068452593.png)

3. 然后，进行处理后的规则化回归的求解（涉及到一些数学上的代换与推导）

   ![1537068850664](assets/1537068850664.png)

4. 二次规划SVR

   ![1537069010172](assets/1537069010172.png)



### SVR的对偶化

1. 拉格朗日的变元推导过程

   ![1537069202182](assets/1537069202182.png)

2. SVM和SVR对偶化的比较

   ![1537069366830](assets/1537069366830.png)

3. 推导后，能够发现在SVR中也存在稀疏解的特征。

   ![1537069441900](assets/1537069441900.png)



### 核函数的总结

1. 线性模型

   - PLA、Pocket（0-1错误）
   - logistic Regression（均方差错误）
   - 软线性SVM
   - 线性SVR

   ![1537069610265](assets/1537069610265.png)

2. 核函数

   ![1537069705810](assets/1537069705810.png)

3. 实用性评价——第2和第4行惯用

   ![1537069783019](assets/1537069783019.png)

- ![1537069875195](assets/1537069875195.png)



















































